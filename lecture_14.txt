Great okay. So welcome to lecture 14. I am David Sontag. I am one of the faculty instructors for this course and for this last lecture of the semester I'll be the one who will be presenting and it'll be a lecture about machine learning in healthcare. As in previous lectures, you may ask questions either via the chat or via Discourse. We highly recommend Discourse because I myself won't be able to monitor the chat other than at a couple of choice moments when I ask you specific questions and I will be monitoring the chat at those instances to see what your responses are. Otherwise, please ask in Discourse and one of the core staff will unmute themselves and ask me those questions. Before I kick off the actual material for today's lecture, I want to just remind us of a couple of announcements. First, the subject evaluations are now open and we have posted a link to the evaluations on the course website. Please complete them by December 14th and this course will be offered again in a virtual format next semester and given that this is still a very new format for us, your feedback is going to be extremely valuable for the next semester's course staff. Secondly, we'd like to emphasize that all course extensions must be completed by Wednesday the 9th. That's less than one week from the normal due date but that's important because MIT rules do not allow us to have anything later than the last day of class be due.

So I'm a computer scientist and over the last 10 years, I have pivoted my research from pure machine learning research to machine learning research which looks at questions motivated by healthcare. And the reason why it's so exciting to be a computer scientist working in the health space now is that there's a wealth of digital health data available. That data ranges from unstructured clinical notes to imaging data, laboratory tests, vital signs, more recently, includes data like proteomics and genomics and even things that we don't traditionally think about as health data but which give us a lens on a patient's health data like mobile activity information or data from a Fitbit type device and the fact that this data is now in digital form means that it gives us an opportunity to use machine learning algorithms both to learn from the retrospective data and to deploy interventions such as clinical decision support on top of that digital data at that point in care.

Health data lives in a variety of different settings and it's really important as we think about how we're going to tackle a few different scenarios that we'll discuss in this lecture today: where that data might come from. For example, one major source of health data is in providers or hospital systems. So for example, many of you students go to MIT Medical. MIT Medical has an electronic medical record and across the United States, the adoption of electronic medical records has increased dramatically since 2008 from 9.4% to well over 85% today. That data consists of some of the aspects that I mentioned earlier such as clinical notes and imaging data. Another major source of health data consists of data that's being collected by health insurance companies and you can see in this diagram here where I show you the three major players in healthcare infrastructure (providers, payers, and patients) that their relationships between them data passes back and forth. So for example, your doctor, when they want to get paid for a service performed for a patient, they send a bill to the health insurance company. So for example, if you're a MIT student, your health insurance company is probably Blue Cross Blue Shield if you're covered by the MIT plan, otherwise it might be by whatever your parent's plan is. Now that bill actually has a lot of valuable information in it about what happened during that visit. So for example, here I'm showing a concrete instantiation of one such bill and you see that.... I'm trying to see how I can get my mouse to show. I need to change the settings. One moment.

[TA]: You can click on the pencil icon in the bottom left and then choose laser. It's the gray icon. [DS]: Thank you.

Can folks see my mouse now? [TA]: Yes we can see your mouse. If you use the laser pointer, it's a bright red dot and it will be a little better yeah but the mouse is fine. [DS]: I can't find the laser pointer option unfortunately. Oh I see it now.

[TA]: A laser up there, not that one. [DS]: Yes, great, thank you very much. All right so over here, this is an example of a bill that's sent from your doctor to your health insurance company to get paid for the services they provide. You see that there are what are called diagnosis codes that refer to the reasons for performing procedures. For example, here there's a code that denotes diabetes, another code that denotes a heart condition called coronary artery disease. In addition, there are several different lines corresponding to different procedures that were performed. Each procedure has a number associated to it, so this is standardized, and, of course, a cost and on the right hand side here, you have an ID for the provider that performed that service.

The fact that there's been such a wealth of digital health data available has been taken note of by industry and we see all of the major tech players now (places like Apple, Google, Amazon) all getting involved in the healthcare industry. So for example, Apple recently launched, as part of their Apple Watch, a machine learning based product which can read a patient's EKG. So it's measuring a patient's heart through a sensor on the watch and can diagnose a number of heart conditions. Google has launched a number of products that are based on computer vision. So for example, they have one which can help diagnose diabetic retinopathy which is a condition caused by diabetes and which goes undiagnosed in many parts of the world due to not having sufficient number of doctors who can read those images. Amazon has released products on their cloud platform which allows hospital systems to upload their clinical notes and it'll perform a number of natural language processing on top of those clinical notes to help with, for example, that type of billing that I showed you earlier: which diagnosis codes to submit to health insurance companies. 

There are also a number of startups working in this area. So for example, a couple of my favorite startups are looking at how one can change pathology or medical imaging by developing devices that can be used by less trained physicians (for example, nurses instead of trained technicians) to do, for example, imaging of the heart and this is going to be very impactful for starting to move medical care away from hospital settings and closer to patients and furthermore, so really starting to fill in the gap in many places in the world where there simply aren't enough trained technicians. And these startups are ranging from a number of different fields such as those imaging fields that I mentioned but also areas like mental health and improving communication between patients and providers and improving quality management and so on. So in today's lecture, I'm going to be doing a number of brief case studies where we're going to dive into a few of these application areas of machine learning healthcare from the lens of the material that you learned from lectures 1 through 13. I'll start out with an example of supervised machine learning for risk stratification. Then, and that'll be the vast majority of the lecture, then I'll talk about a use of unsupervised learning, in particular k-means clustering that you saw in last week's lecture, and I'll show how one can use that to discover subtypes from asthma which you might recall was one of the optional questions in the lab last week. Finally, I'll give an example of reinforcement learning in healthcare and show how one can use that to better manage patients with septic shock in hospital environments and I'll close with a couple of comments about what makes healthcare different from many other application areas of machine learning and also some suggestions for future courses you could take to further learn about machine learning here at MIT.

So let's start with the following scenario: as I imagine many of you have been tracking, we have been getting very close to having a vaccine approved in the United States for coronavirus and over the next couple of months, there is going to be an enormous effort to get our population vaccinated. But in the first couple of months, there won't be enough vaccines for everyone to be vaccinated and so a number of ongoing efforts are trying to think through what population should one vaccinate. Questions about: should one vaccinate first health care workers? Frontline workers? Elderly? And so on. And I'm not going to focus on the question here of who should get vaccinated but I want us to be thinking about: once that decision has been made, what can we best do to achieve that goal? So in particular, let's think about an elderly population. Almost all of the current guidelines are going to prioritize individuals above the age of 65 very soon. In the next couple of months, they will be eligible for getting a vaccine. But not all of them will know or prioritize getting the vaccine themselves despite the fact that they're eligible to get it. So we can imagine that the government might start a service where they are going to have a team of call workers that are going to be picking up the phone and calling elderly individuals who are most at risk of having complications due to Covid and working with those individuals to try to get them to a local clinic where they could be vaccinated. You could also imagine having nurses sent to patients homes to do vaccinations at home in some cases but one of the major challenges... Give me one moment.

One of the main major challenges in doing such outreach is that it's very costly and one might only have funding in order to, for example, send nurses to a certain number of individuals homes or facilities and that leads to a really important question: how should one prioritize those resources? So for example, one question, one way of trying to frame this where machine learning might be able to provide some light is that we could ask: who are the individuals who are most likely to have poor outcomes were they to be infected with Covid, with the coronavirus? Now it's very difficult to try to think through the question of who's likely to have poor outcomes from a machine learning perspective because we have poor data on the base denominator: who actually was infected. However, we do have very good data on who was hospitalized and a slight reformulation of this question in order to try to tackle it with machine learning is to ask not about who has poor outcomes of those infected but, of those who are hospitalized of which only a small fraction of them end up having poor outcomes, which of those end up having poor outcomes such as admission to intensive care unit or death?

And this, one can start to try to tackle with data that we have because there are very good records of who's been hospitalized and who has poor outcomes among those who have been hospitalized.

So this question has been studied by a number of different authors already and, for example, recent work from New York City, from Korea, from California, have looked at questions such as, of patients who've been hospitalized, what factors, whether it be past medical history or factors that patients present with when they're hospitalized, lead to those poor outcomes? And a number of different factors were surfaced. For example, older age, and that's one of the reasons why individuals over the age of 65 are being prioritized, past conditions such as hypertension which means high blood pressure, obesity, diabetes, and so on. So one approach that one might take is we're going to use machine learning algorithm to try to predict these poor outcomes from electronic medical records and then prioritize individuals based on those predictions. But the challenge with using that approach is that electronic medical records are very siloed and so such a machine learning algorithm would have to be deployed de novo at every single institution which is going to be very slow, expensive, and unlikely to be possibly rolled out in a short period of time and so this is where, in this hypothetical scenario, one of the most important machine learning questions comes to mind, which is: what data do you have available and how can you make use of that data despite the fact that it might be very imperfect? And so what I'm going to do is I'm going to walk you through a hypothetical scenario where we think through what data to use, how we would process it, and how we would evaluate the result or try to tackle this problem. So I'm going to propose that what we should be using for this is data that's available at a national scale. In particular, health insurance claims. Remember I told you that providers have to submit bills to their health insurance company in order to get paid and I'll show you an example of what those bills look like. Well the biggest health insurer in the United States (in particular, the one which is most relevant to elderly individuals) is the Center for Medicare and Medicaid Services and CMS has data on most individuals, most Americans over the age of 65. Whether you're poor, whether you're rich, almost all individuals in the United States are covered by Medicare once they reach a certain age and, thus, if one thinks about how one could very quickly both train and deploy a machine learning algorithm that could stratify at a national scale that data is perhaps where we should be looking.

So here's the hypothetical study design which I want us to think through as part of this. Let's take all data from patients hospitalized with COVID-19 from March to July in the United States, data that's available from Center for Medicare and Medicaid services. We're going to extract features from the data pre-hospitalization and we're going to attempt to predict whether our patients have poor outcomes during hospitalizations. In particular, we'll design a binary classification task where we have a label y which is 1 if the individual is admitted to the intensive care unit or expires (dies) during the hospitalization and 0 if they are discharged alive without having had to be admitted to an intensive care unit.

And again, as an important disclaimer, I have not done the study that I'm proposing here. This is just a thought exercise for us thinking about how we would try to tackle an important problem today using machine learning.

So let's now start thinking about how one would try to derive features from this data set. Now I just said that the labels are going to be derived from that hospitalization and we're going to be focusing on just patients who have been hospitalized with Covid-19. That should say 19 not 10. Well we could go back in time to pre-hospitalization and look at all the types of data that would be available to the health insurance company. In particular, as I mentioned, every single visit with a health provider is going to have some records to it. So if the patient has gone to their primary care physician and they have high blood pressure noted as a diagnosis code, we will have a record of that. If the patient goes to CVS pharmacy and fills a prescription for high blood pressure, we will have a record of that. If the patient has a telemedicine visit with their dermatologist, we will have a record of that.

So the first question that I want us to be thinking about now is: how do we take this time series data and try to construct a feature vector from it? And notably, you can see here that some of the factors which have been discovered in earlier work in, for example, using electronic medical records do show up here. We mentioned how hypertension is a factor which seems to be predictive of poor outcomes and we see that hypertension which is high blood pressure is recorded in previous patient visits so that's something that we might be able to distill from the data. But if you dig deeper into the literature, you'll see that it's not just the patient having hypertension which is predictive. In fact, it's having complicated or uncontrolled hypertension meaning the patient is not being well managed for their hypertension. If their blood pressure is high despite the fact that they are on medications or if they're not taking the right medications, those are the patients who tend to do poorly and, importantly, you have that information here. So you have records of whether medical patients are on medications, you have records of how often they're seeing physicians, and although we don't have direct measurements of whether the patient's hypertension is being controlled appropriately or not, one might be able to try to pull that out of this data via a algorithm that can detect very subtle signal and high dimensional data such as a machine learning algorithm.

So to dig a little bit more into the data, here's what it actually looks like and what I'm showing you is a patient timeline and I'm showing you, with each bar here, when a data element is observed in the data for this hypothetical patient. So I told you that we have medical claims, with those medical claims we have these diagnosis codes. Diagnosis codes are encoded in an ontology known as ICD-10, this is a hierarchy where the top-level hierarchy denotes, for example, neoplasms for cancers. There are another set of codes corresponding to diseases of the blood, another set of codes corresponding to endocrine disorders like diabetes, another set of codes corresponding to mental health issues and if you dive deep into this hierarchy, you'll see that it is extremely detailed: we're getting really rich information about the diagnosis, the past diagnosis of patients. For example, there's even a diagnosis code for “bitten by a turtle” or “bitten by a sea lion”, “struck by a macaw”. These are some of the more rare codes but it gives you a sense of the richness of the data that could be encoded in these health insurance claims. We also know for every visit what specialist the patient visited: was it a primary care doctor? Was it an endocrinologist? A dermatologist? And we know where the visit was. Now I talked about data being derived from pharmacy records and these medications will have records of a code for the specific medication (that's called the national drug code or NDC code). If you take a medication off of your medication cabinet and you look at the box, you'll see that NDC code listed in the box and so every medication has a unique identifier which allows us to think about how to construct features from the presence of a medication in a patient's medical record. We know the number of days supplied and we know the provider who prescribed it and when.

So a traditional approach to feature construction might take some of the factors that earlier work using electronic medical records had shown already to be predictive. You might take the patient's age, their gender, you might try to derive from all of the data that I showed you whether the patient has hypertension, for example, looking at a set of hypertensive codes, looking at medications that are used to treat hypertension, and saying if any of this set of codes or any of the set of medications are present, then the patient has hypertension, yes or no, 1 or 0. You could do the same for other conditions like diabetes, cancer, and so on and construct a feature vector of 20 or 30 or 40 different features which are risk factors that were conjectured to be predictive of patients having poor outcomes when hospitalized with COVID-19. So this would be a traditional approach to feature construction and one of the major challenges with these types of traditional approaches is, first, that they're very time consuming to create. So that notion of coming up with the list of things and then seeing how does one derive whether a patient actually has hypertension by “what is the set of diagnoses supposed to look at”, “what is the set of medications to look at.” That takes a lot of time from a data scientist or from a domain expert. The second challenge with these more traditional approaches is that they miss a lot of the subtle detail around the patient's condition. So I spoke about how it's not just whether the patient has hypertension or high blood pressure that's predictive, but whether it's not being managed appropriately and that is something which is really, really hard to derive from the patient's data manually. There's simply no good characterization that works well for large numbers of patients. So the approach that we're going to take in this hypothetical example is one which is more of a black box machine learning approach. And although this is a hypothetical example, this is one which I have used very similar approaches on exactly the same sort of data for a number of other non-COVID related conditions and so I know that this type of approach works. So the analogy that we're going to be drawing is just something that we've seen throughout the course so far when we've talked about, for example, text classification. We said, “how would we take a text document which has a number of words and, for example, learn a classifier to label an email as spam or not spam?” And we said that a very simple approach to try to do that might be to create one feature for every word in the vocabulary with an indicator of whether that feature is 1 or 0 which tells us “did that word appear in the email or not?” Now for this type of data, I'm going to recommend a very similar approach to extracting features from the patient's longitudinal health records: we're going to first create some features just from some basic demographics like the patient's age, gender, and so on. Then we're going to look at a number of other features that look at their health insurance coverage and I'll come back to why that’s relevant in just a couple of moments. Those two are are sort of the more standard set and everything else they'll be referring to now are what I'll call as the bag of words features. So for example, we'll create one feature for the service place where patients are going. So, have they been to a primary care doctor? Have they been to an urgent care clinic? Have they been to a hospital? Have they been to a regular doctor's office? And for each of these service place categories, we're going to just create a single binary indicator for “has the patient been to that service place ever?” One or zero. Now we'll do the same thing for these other categories. For example, of all of the medications, we might look at the thousand most popular medications. We're going to create a single binary feature for “was this medication ever filled?” Yes or no. We’re then going to look at all possible procedures that could have been performed or let's say the top 1,000 most common procedures and we'll say “has this procedure ever been performed for the patient?” Yes or no. And we'll do the same for the diagnosis codes so we'll look at all of the different, let's say top 10,000 ICD-10 diagnosis codes, and we'll look at “has this diagnosis code ever been recorded for a patient?” Yes or no. Now you might be wondering whether the code has been recorded or not only tells you part of the story. For example, whether you fill this medication in the last three months might be very different from whether you fill the medication three years ago and so the way that we're going to bring in the temporal information here in this hypothesized approach is by redoing this whole procedure I just mentioned, now once for every time window. So we will create one set of features by performing that procedure I just showed using all the patients past medical history. We'll then repeat the process now restricted to just data from the past 24 months and we'll repeat the process using data from just the past six months. We will then concatenate each of those feature vectors together and we get the overall set of features that we'll use to predict the patient's outcomes. Overall we might have tens or hundreds of thousands of features and so we're going to need a machine learning approach that can deal with the fact that we're in a very high dimensional setting and can prevent us from overfitting. I'll just pause briefly to see if we have any questions.

[TA]: I'm done so far yeah. [DS]: And I saw a comment about disabling annotate on the screen, has that been done?

[TA]: I think that's for you. So if you go to view options on the top, you should just like where you're sharing the screen just get rid of the annotate option.

[DS]: Great. Okay hopefully that's done. [TA]: I can still see the option to annotate your screen. [DS]: On the bottom or the top because I don't see it? [TA]: On the top. It should say like you're sharing your screen and then on the side it should say view options and then if you click down it should just disable the annotate, just like uncheck it. [DS]: Hide names of annotators. Did that work?

[TA]: I don't think so. I think you're okay without that option. Okay.

[DS]: Okay so the technique that we're going to propose to use here is one that you've already seen in a recent laboratory where we asked you about how you would tackle these different scenarios of machine learning and one of the options that we had suggested in that lab was doing logistic regression with what was called L1 regularization. So I'll briefly walk you through what I mean by this just to remind us. So as Tamara presented in the lecture on logistic regression, logistic regression could be formulated by the following objective function: we're going to sum over the n data points, our loss function is going to be a negative log likelihood. We're going to use as our predictor, which will give us the probability of an individual having a poor outcome from COVID-19, we're going to use for that a linear model parameterized by a weight vector theta. That linear model is going to feed into a sigmoid which will give us the probability of 1, which is going to be a number between 0 and 1, and we're going to evaluate the likelihood using that probability of the true label, whether the patient truly had a poor outcome when hospitalized with COVID-19 or not, and that label is given to you by y^(i) for the i-th patient. So that is the unregularized logistic regression objective function and what we saw in class is that one way to try to prevent ourselves from overfitting would be to use L2 regularization where we add on to the objective function a penalty for the squared norm of the weight factor theta. And just to remind you, by the squared norm what we mean is we sum over the different dimensions of the weight vector of that weight, the d-th weight, squared. Instead of that L2 regularization, what we often do using this type of data is L1 regularization and L1 regularization has the property that it tends to result in very sparse solutions and the reason why that makes a lot of sense as a type of method for controlling for the number of high-dimensional features is because in this data set, by the way that we constructed the feature vector, most of the features are irrelevant or not useful and that we expect that they're only going to be a small number of features that are actually predictive of this poor outcome. So by encouraging the learning algorithm to find a sparse weight vector, it's using some prior knowledge we have that the hypothesis space that we want to be searching within is one of sparse weight vectors and as a result, we're going to be able to prevent ourselves from overfitting to the large weight vector even if we have a very small number of labeled data points. So this L1 regularization, if we look on the right hand side, is defined as summing over the features of the absolute value of the d-th weight, theta_d, so you should be comparing this absolute value to the theta squared term shown on the bottom. We can then use one of a number of different optimization algorithms, for example, variance of stochastic gradient descent, in order to minimize this overall objective function. Now intuitively, the reason why using this L1 norm results in a sparse weight vector is because when you're minimizing that objective function, you can think about the first term in the objective function over here, this L negative log likelihood, as some convex function: it's a convex function when we're using a linear model as we are here and we could think about what are the solutions that it could reach if we were restricting the weight vector to, for example, have any constant value according to the L2 norm or any constant value according to the L1 norm. Intuitively, you could think about trading off. If you were to trade off this value being 10 or this value being 10, what solutions do that enable you to find in terms of the original objective function? So on the squared norms case, the picture you should be having in mind if you had just two weights, theta_1 and theta_2, would be something like this: so if that squared norm were equal to 10, then the weights would have to be something along this circle. On the other hand, if the L1 norm were equal to 10, then the weights would have to be something along this diamond shape. So again, this first axis we'll call theta_1, the second axis theta_2. Now if you look at the left hand side, the solution that minimizes the objective function that lives along the circle is sort of this solution over here, whereas in the right hand side, the solution which minimizes this objective function according to that constraint is actually at this corner point and that's one of the reasons intuitively why using this L1 regulation tends to result in sparse weight vectors as a solution. Now once one has learned the model, the next thing that we typically do is start looking at the model and trying to introspect: does it make sense? And the reason why this is so important is as a sanity check for whether we set up our problem appropriately. Often we will find by inspecting the weight vectors errors in our machine learning formulation. For example, we might we might easily detect that that there was label leakage by recognizing that some weight which really doesn't make sense is much higher weighted and this type of introspection by looking at what features have non-zero weight is much easier to do in the setting where you use a L1 regularization as opposed to L2 regularization because there are many fewer weights than features that have non-zero weights, you tend to just look at all of them. Now the second thing which is important in thinking about how we would actually use the results for solving the original problem that we set out to solve, which recall was prioritizing outreach to patients who are eligible for having a vaccine. We want to figure out who we should be contacting in order to help them, for example, or get them to their local clinic. We need to understand, well, as a function of the number of people who we can actually outreach to, how many of them might actually have poor outcomes according to the predictions made by this algorithm? And to character that, we use what's known as the receiver-operator characteristic curve. You'll see this often in the machine learning literature under the acronym ROC curve. Now the roc curve takes your predictive model. Remember, here we use logistic regression so we get a probability out and it's going to look at if we were to threshold that probability at a variety of different values, what true positive and false positive rates are achievable by that threshold. Here I'm showing you just two hypothetical models. For example, a model which is trained using just those traditional risk factors that I showed you originally and then the second model that I proposed where I said we're just going to include this bag of words feature vector which I'll call the full model. So the roc curve will plot, for every possible choice of threshold, we're going to look to see, okay, if we were to make those predictions according to that threshold. So let's say if we put a threshold at 0.5 and we said everyone with a probability higher than 0.5, we're going to predict to be 1, everyone with a probability less than 0.5, we're going to be going to predict to be 0 and we ask: well of the ones we predicted, of the ones who were truly 1, what fraction of them, of the ones who were predicted to be 1, what fraction of them truly went on to have poor outcomes? That's what's known as the true positive rate and if we look at of the ones who are predicted to be 0, what fraction of them went on to not have poor outcomes, that's the false positive rate, and that gives you one point along this curve and if you're to change that threshold from 0.5 to 0.6, you get another point along this curve. Now one could try to summarize how good one algorithm versus another algorithm is by comparing these two different curves and one statistic that could be useful for trying to compare one curve versus another is the area under that curve and that is often reported in the literature as the area under the ROC curve or AUC. So for example, a random predictor would be shown by this dotted line here and it would have an AUC of 0.5 whereas this one that I'm showing you here would have an AUC closer to, let's say, 0.7. Now a different way of interpreting the area under the ROC curve, although I won't derive this for you here, is that it's the probability that if you were to take two patients, one who had a label of 1 and one who had a label of 0 and ask “if you're to take two patients who have a label of 1 and patient who has label of 0, does your algorithm rank them correctly? Does the patient who has a label of one, is their probability according to the output of your logistic regression higher than the probability given to you by the patient who has a label of 0?” If you look at the fraction of times that their ranking is correct, that turns out to be the area under the ROC curve. And where you want to be is up here in the top left corner. So you would like to have zero false positives and all true positives and that would have an area under the ROC curve of 1. Now you can see that a random model has an area under the ROC curve of 0.5, A perfect model has an area under the ROC curve of 1. Now if we think about the actual application that we set out to try to solve, we're not going to have resources to reach out to a 100,000… Sorry, we may not have resources to reach out to five million individuals because there might not be budget for that. Instead, we might only have resources to do this intensive reach out to, let's say, 2 million or 1 million individuals, and so we don't really care so much about this right hand side of the curve, we care about what's going on over here on this side of the curve and there's a different statistic which is often used to try to characterize that and it's known as the positive predicted value. So the positive predictive value is a measure of, if you were to take your sorted ranking, so we're now going to take the model that was trained, we're going to apply it to patient data from December 2020, and we're going to get a ranked list of individuals who, if hospitalized, who is most likely to have poor outcomes, and then we're just we're going to say “okay we have money to perform outreach to a certain number of these individuals to try to help them get vaccinated.” For example, we might have enough, we might be able to reach out to 100 individuals, we might be able to reach out to 1,000 individuals, we might be able to reach out to 10,000 individuals. And so what's relevant is, of those 100 individuals, 1,000 individuals or 10,000 individuals, what fraction of them actually went on to have poor outcomes if they were hospitalized with COVID-19? And that's what the positive predictive value measures: it's the fraction of individuals of a predicted set that actually have the 1 label versus 0 label and you want that number, of course, to be as high as possible. When you then go to a decision maker (for example, you might go to Congress and ask for more budget), you might describe your approach for your return on investment, in some sense, of how many more people you will be able to reach out to if you were given this much more budget.

Now I've given you a very hypothetical example and, as I'm sure you have been thinking through, there are number of subtleties to how one would try to use this machine learning approach and the real world really is messy and imperfect. So for example, I'd like to hear from your thoughts: will model trained using data from July be useful in December? Has anything changed? So if you could take out your chat and send me a private message, I'd like to see your thoughts about whether there are any concerns with using a model which is trained using data from March to July to learn who is likely to have poor outcomes from a COVID-19 hospitalization and then taking that model and deploying it now in December or January using data up until now. Where might using that approach go wrong? I'd like to hear some responses. You can send me private chats too and I'll just wait a moment to read, I'm getting a couple but I'll wait for a few more responses.

I'm getting some really interesting responses. I'll wait one more minute to see what else we get.

All right, so some of the responses we heard from our fellow students are that, well, first of all, the state of the world might be different for a number of reasons. If you apply the model in December, for example, it's now winter time, and so both of the data might look different. For example, patients visits to doctors might be different in the winter time versus in the summer. Also very importantly, the COVID-19 strain might have changed from July to December: there may have been mutations and so, as a result of that, perhaps a different set of people might be at highest risk of having poor outcomes. Another very important problem is that there may have been new treatments as well that have been discovered from July to December and so that might also have affected who is likely to have poor outcomes. So I'll just mention a couple of these here, but you mentioned many others, and these are all really good points. So these are things that we're going to have to take into account when we want to use such an algorithm. So for example, you might think that the data looks very different because of some of the, let's say, weather changes. So we might say, “okay, well one way to try to address that problem is to only use data up until, let's say, March 2019.” So we're going to take only the patient's data up until March 2019 to make the prediction even if that prediction we're making in January or February of 2021. I meant to say up to 2020 instead of 2019. And so there you might be using less information (you might be missing out on some of the most recent data from patients), but the upside of that is that you have a consistent set of features that don't change much as we go into the future. Now the second problem that you mentioned is that there are, let's say, new treatments and that is, of course, also a big problem and so one thing that one can do is one could take the model that was trained using data up until July and you could evaluate how is it doing at various points in the future. For example, you could look at what is the area under the ROC curve when you take that model, that same model, and you apply it to patients in August, September, October, November, December, and you can look to see, well, despite the fact that treatments are changing across time, is the relative ranking among patients still relatively consistent? So if the area under the ROC curve is relatively the same across time, it might be that some patients' risks go down. It could be that the overall probability of everyone is shifted down a little bit due to the treatments, but so long as the relative risk across patients is the same, then the model might still be useful. But that's an example of a sanity check that one might want to do and, of course, introspection into the model can also help with that. Okay so that's all I want to say about that example and now I want to move on to thinking about clustering and a use of unsupervised learning for healthcare. So recall back to lecture 13, last lecture, where Tamara presented the k-means algorithm. She gave this example where there are two features x_1 and x_2, longitude and latitude, there are a number of data points, n data points, and critically, in the k-means algorithm, there are no labels: our goal is to discover some structure in the data. The first step of the k-means algorithm was to initialize some means. Here we chose 1, 2, 3, 4, 5 different means so there will be five clusters we get out. Then the second step of the k-means algorithm assigned every data point to their closest mean and so that's what you're seeing here by the colors. We're then going to average the data points assigned to each mean in order to get a new mean for that cluster and then we're going to repeat this procedure over and over again until it converges and you get a final clustering algorithm out. So what I'm going to present next is an application of the k-means algorithm to solve a problem that had been presented to me, actually, originally a few years ago by a pharmaceutical company that was really interested in studying asthma and this is a problem, by the way, that some of you might have noticed was the last optional question of the lab last week. So the problem is that 5% to 10% of people with severe asthma remain poorly controlled despite using the best therapy that's currently available and so we'd like to think about: can we better understand asthma and can we think through how we could design and evaluate new treatments for asthma? In this paper published in a medical journal, The Lancet, a few years ago called “New targets for drug development in asthma,” they asked the following questions: what are the processes, genetic or environmental, that underlie different subtypes of asthma? What are markers of disease progression or treatment response? And why is it that some patients are less responsive to conventional therapies than others? So we're going to try to answer these questions or some of these questions by using a k-means clustering algorithm on data from asthmatic patients and the output of the algorithm is going to be a new set of clusters which... You don't have to understand this slide, we're going to dive into in just a moment, but this is just a slide, a picture from this paper published in 2008 which characterized three different families of new subtypes of asthma and that's what we're going to aim to discover through this analysis. So they're going to be three data sets used in this analysis. All three are from a non-smoking population and the first data set is of 184 patients recruited from primary care practices in the United Kingdom. The second data set is 187 patients who were treated in an asthma clinic, so these are patients who potentially have more severe asthma because they're not being managed just by their primary care doctor but by a specialist. And then finally, we're going to have a third data set of 68 patients who had undergone a randomized control trial comparing two different treatments. That third data set we're not going to use for a few minutes. We're going to start by using those first two data sets to try to do clustering to see: can we discover any interesting structure in the data, see how patients might differentiate across different asthma conditions. Here's just a very quick analysis of those three cohorts. So each column here is describing one of those three data sets. Focus on the first two columns. In the primary care cohort, there were 184 patients and a secondary care cohorts, that is patients who are managed at an asthma clinic, there were 187 patients. There were a little bit more female patients in the second cohort, so 65.8% in the second, in the asthma clinic cohort. The age distributions were relatively similar: an average of 49 years old in the primary care cohort, an average of 43 years old in the secondary care cohort and so on. And so this gives us some intuition about who are the individuals but there's been no clustering yet. The first thing we're going to do is we're going to take the primary care cohort, these 184 patients, we’re going to run a k-means algorithm and I won't walk through how we choose the number of clusters, but just believe me, we're choosing three clusters here. So we initialize with k = 3 means, we run the k-means algorithm, and we're now going to analyze the results. Now the first thing we're going to do here is we're going to recognize that here, we're using a relatively small feature vector. In particular, every row here corresponds to one of the features that went into the k-means algorithm. We have the gender of the individual, we have their age, the age when they had an onset of asthma, their body mass index, a measure of their lung function (that's measured by this biomarker called FEV_1 change), how much corticosteroids they inhaled as part of their typical therapy, how often they were admitted to a hospital or emergency room, and how many severe asthma exasperations they had in the past 12 months. So each one of those is one of the features and, again, we're doing this clustering just in the primary care cohort and in this first column here, I'm just giving you the average of the feature values across the whole entire cohort. Now the way that we're going to understand or visualize the output of the clustering algorithm is by looking at the mu_1, mu_2, mu_3, meaning the cluster centers, cluster means, of the three different clusters. We're also going to look at the variation or variance of each of the features among the data points assigned to that cluster and that's going to be a number presented in the parentheses here. So, we get three clusters out: the first cluster has 61 patients, the second cluster is 27 patients, and third cluster has 96 patients. Let's start to try to analyze these clusters by looking at these features. The first thing that is immediately apparent is that in cluster 1, the age of onset of asthma is substantially smaller than in other clusters. In cluster 1, patients tended to develop asthma at roughly 14 years old with a standard deviation of 15 years compared to clusters 2 in clusters 3, where patients tend to develop asthma in their 30s. We also notice that in cluster 1, that on average patients have had one previous hospital admission and almost two severe asthma exasperations in the past 12 months and that should be compared to the averages in the whole cohort shown in the first column. And so we're going to call cluster 1, the early onset cluster, patients who have early onset asthma, and these patients actually have pretty exasperated asthma. You can see that by their large number of hospital admissions. These names you see in the very top here are names that the analyst has given to the cluster by analyzing these means and comparing it to the overall population. Cluster 2, we see, is overwhelmingly female. So 81 of individuals in cluster 2 are female and they also tend to have a much higher body mass index, so this is a bit more of an obese population.

And cluster three is generally healthy. These are patients who have asthma but if you look at the bottom three features here, on average they've basically not been to the hospital at all and they have had very few asthma exasperations. So these are three clusters that we found through k-means clustering on this one data set and the next thing we're going to do is see how robust it is. So we're going to take the second data set of patients who are treated in the asthma care clinics and we're going to repeat that clustering, the same clustering procedure: initialize means randomly from scratch and re-run clustering. The set of features are very similar but not identical to the previous data set which is why we don't attempt to, for example, throw together all the data and cluster them jointly, it's because we have a slightly different set of features. So we run clustering here. For this data set, the authors chose to use four clusters. I'm not going to comment on that but we saw in lab and in the notes for the clustering how there are a number of different methods for trying to choose number of clusters such as, for example, looking at k-means objective as a function of cluster size increasing. So here, despite the fact that we redid the clustering from scratch, what these authors found is that very similar clusters seem to arise. So when they analyzed these four different clusters, they found that three of the clusters ( what they're labeling as cluster 1, 2, and 3) corresponded almost identically to the clusters that were found in the previous cohort but now there is a fourth new cluster, what they're calling information predominant, which are our patients who have substantially worse asthma and that makes sense as well because this is a slightly different population as the previous population: these patients are patients who are being managed by experts in asthma and so there tend to be sicker patients and so this fourth new clusters is the sicker set of patients. Okay, so now we're starting to see something really interesting: we're seeing how these first three clusters were pretty robustly discovered across two very different data sets. So that starts to give us some confidence that there's some significance to those clusters, but now we're going to try to take that the next level and see: can we try to see if those clusters are actually meaningful in changing something about treatment or seeing how effective different treatment might be for patients within those clusters? And that's what we're going to start to use now, the third data set. Now the third data set only has 68 patients. So it's substantially smaller than the first two and if we were to do clustering, which we'll do on these patients, we should really question the robustness of those clustering results because of the small number of patients and that's where the alignment with the previous two results is going to end up being important. I'll come back to that in a moment. Now for these 68 patients, these patients were followed over 12 months and half of these patients received standard clinical care, but the other half of the patients received a new type of treatment. In particular, what we're going to call the sputum treatment and this treatment strategy involves regular monitoring of the airway inflammation using the patient's phlegm and changing the amount of steroid therapy in order to try to maintain a certain level of white blood cell count from the patients as observed in the patient's phlegm. So that's a new treatment strategy and the question is how well that treatment strategy works. Now the original study, the original randomized control trial involving those 68 patients, found no statistically significant difference between these two treatment strategies meaning if you look at outcomes such as hospitalizations or number of exasperations, there was not a statistically significant difference across the two different sets of patients who got one treatment versus the other. However, what you ought to wonder about is: there might have been variation in the treatment response. Maybe, some patients perform, do best, under that first treatment strategy and other patients do best under that second treatment strategy and so what we're now going to do is we're going to re-analyze these results, trying to separate out patients according to those three different clusters. So the first thing that was done is taking the baseline data, so the data pre-treatment, and assigning patients to these three different clusters and we now have a pretty rigorous definition for what these three different categories of patients should be based on the clustering done on the first two data sets. So we're going to categorize every patient into one of these three categories and then we're going to look at what happened according to those two different treatment strategies. So what you see here is that along the three different sets of patients, the first category of patients (what the authors called obese female cluster), if you look at the outcomes, for example, severe exaspirations and number of times that they had to start oral cortical storage which is which is a measure of severity, both of these numbers are very low. So these are patients who were not really affected by either of the treatment strategy, there's no statistically significant difference. The other two clusters is where the interesting things happen. So in particular, if you look at that third outcome, you see that in the first of these clusters, the inflammation predominant cluster, in one of the treatment arms, so the regular clinical practice, you see that under the first cluster, patients do well under the typical clinical practice but on the second cluster, they do poorly under typical clinical practice and you see the exact opposite in terms of the patients who got the other strategy. So if you were to average these two numbers, it looks like the treatment doesn't make much too much of a difference. Right if you compare the sum of 9 + 0 to the sum of 2 + 6 which is 8, 9 versus 8 doesn't look very different. On the other hand now, if you break down the patient according to these two different categories, you see that for one of these subpopulations, it looks like this typical clinical practice does much better than sputum because we want this number to be lower. Sorry I think it's the opposite: we want it to be higher so the sputum category, the sputum arm, does much better for this cohort whereas for this cohort, the typical clinical practice does much better as a treatment and so this now suggests that maybe if one were to approve this new treatment strategy, one should approve it only for these sub-cohorts of patients for whom it looks like they respond the best to that treatment and this is just one illustration of how one can use k-means clustering to try to guide who should who might benefit the best from treatment.

So now I'm going to move on to the second to last section of this lecture which is about reinforcement learning of treatment policies. So think back now to lecture nine where Tamara introduced market precision processes and then lecture 10 where she introduced reinforcement learning.

So Markov processes involved, first, a specification of a state space and in the simple example that she gave in lecture nine, the state space was very simple. This is a farming example and the state space was either there's poor soil or rich soil and so every farm is in one of these two states. Then, one has to specify a transition distribution. So according to what action is taken, there's some probability of transitioning to either staying in the same state, which is denoted by these self loops, or transitioning to a new state. So for example, the transition distribution for the plant action if you were to take the action of planting. Then if you started out in a rich soil state then if you were to take the plant action from the rich soil state, with probability 0.9 you're going to end up in a poor soil state. On the other hand, if you take the plant action starting in the poor soil state, there's an extremely high (so probably 0.99 now) of staying in a poor soil state, very unlikely that by planting you turn a poor soil into a rich soil. And one can talk about the transition distribution for different sets of actions such as a fallow action.

So that's the state space, that's the action space. We talked about the transition distribution. The transition distribution is given to you by a starting state, an action, and then asking about the probability of ending up in a new state and so you have a probability or a real number between 0 and 1 for every cross product of starting state, action, and ending state. Now a Markov decision process also has a reward function which tells you for every state and every state that you end up in and every action that was taken, what is the reward for ending up in that state having taken some action? So for example, in lecture, Tamara hypothesized a reward of being in a rich soil state and taking the plant action of 100 whereas the reward of being in the poor soil state and taking the action of plant was 10. She also specified a discount factor but for health care settings, the discount factor which is used to discount the effect of rewards that were long in the past is irrelevant. In some sense we care about the full set of rewards for patients and so we're going to think about the discount factor as just being 1. So I won't be talking about discount factor in any of the subsequent slides. Okay so this is just a quick reminder of Markov decision processes. Now let's think about how we might use Markov decision processes in healthcare to try to provide decision support to clinicians as they manage patients who have cancer or they try to manage patients who have a very critical illness. And the goal, what we'll be describing, is to think through how can we learn a policy pie which takes a state and proposes an action and when we try to implement this in a healthcare setting, you think about this as taking data, learning these policies, and then using these policies to provide decision support for clinicians. So if our policies says, “we think that prescribing the patient this medication which would be an action would result in the best future set of rewards,” then one might suggest to the clinician: maybe you should be prescribing this treatment because we think the patient will respond best in the long term to this treatment. So that's an example of what a policy might be and how one would use it. So the case study that I'll be giving to you here is from that of managing what's known as septic shock. Septic shock is a condition, it’s the second leading cause of death in hospitals, and it's caused by infection and that infection the patient's immune system attempts to fight the infection but at the same time as the immune system being activated to fight infection, often \ the immune system also ends up affecting the patient's organs. That can lead to organ failure and ultimately death and so when one wants to try to manage sepsis, of course the first thing to do because it's caused by an infection is to try to prescribe an antibiotic.

Then, however, antibiotics alone tend to not be sufficient for managing sepsis and there's a number of other things that one has to try to do to try to keep the patient alive once they get into this state. So for example, a patient might be put on mechanical ventilation in order to help with their breathing, patients might need sedation because they might be very uncomfortable due to the mechanical ventilation which they were just put on, giving them sedation might have reduced the patient's blood pressure and as a result of that, one might have to give vassal pressures which is the machine you hook them up to in order to try to artificially increase their blood pressure and so on. And so if one thinks about these series of actions that would need to be taken in order to optimally manage a patient with sepsis, it corresponds to a large number of actions across time and for any one patient, you only observe one set of actions. So for this patient that I'm showing in the orange line here, they receive mechanical ventilation, let's say at time three hours, then they did not receive sedation and then at, let's say, four hours they received vasopressors and so on. And had something else happened to them, had they taken a different trajectory through this path of decisions, then they would have a different set of outcomes but we only, of course, observe one actual patient trajectory in the data set because doctors did one series of actions to them. Had doctors done a different series of actions, then we might have gotten a different set of outcomes. And one of the challenges in trying to learn an optimal policy for managing sepsis is that there are a large number of possible actions but only some of them are observed in the data. I'll get back to that in just a minute. So in order to try to tackle this, the first thing that we're going to try to do is define the state space, the set of actions, and the reward function and whereas in the earlier part of the lecture I was giving you a hypothetical scenario around COVID-19, what I'm describing here is a paper that had been published two years ago in Nature Medicine. I have the reference in the very bottom here. So for the state vectors, what they did is they derived a feature vector for each point in time which looks at both: what are the most recent and past actions that were taken (so for example, path medications), looks at the patient's vital signs (for example, what is their current heart rate? What is the current blood pressure? What's the current oxygen saturation? And so on). And you get this one high dimensional feature vector describing the patient at that one point in time. Now, in order to apply the algorithms that you learned in this class which were for discrete Markov decision processes, we want to get a finite set of states out and so what these authors did is they took that feature vector describing the continuous valued feature of the state of the patient at every point in time, they're taking the union of all those different feature vectors from a single patient at different points of time across patients. So now, one data point might correspond to patient three at time step ten, for example, and we're going to do now k means clustering of all of those different continuous valued future vectors and what we would get out are, let's say, 500 different clusters and we're now going to define a set of states corresponding to 500 discrete states. Every patient at their point in time is assigned a number corresponding to which cluster that data point went to in k-means clustering and so now we have a state space of 500 different states that we'll use in defining this Markov position process. Now the actions were the actions that I described earlier. So for example: do you put the patient on mechanical ventilation? Yes or no. Do you give the patient fluids? If so, what amount of fluids? So you might imagine three different levels of fluids and if you look at the combination of these two different types of actions, that itself defines the action space. So one action corresponds to a few of these different decisions. I can't remember the exact number of actions but let's say there are 20 or 50 different actions. Each action, again, tells you “start or stop ventilation?” plus a level of amount of fluids to give the patient. Now for the reward function, one wants to, of course, keep this patient healthy and so “how does one characterize healthy?” is one of the key design choices in setting this up. And different choices of reward functions will result in very different policies that are learned. So for example, one might just use a very simple reward function which ignores the reward at every intermediate state and just looks at the reward at the termination states where, in this case, a termination state corresponds to either a patient dying while they're in the hospital or then being discharged and then surviving at least 30 days or dying within 30 days. Each one of those will correspond to some reward function where, of course, we're going to put a very high negative reward on the poor outcomes. Now one might also be interested in having more intermediate rewards along the way and this is one thing that you saw could be very helpful in learning a good policy is this type of reward shaping and so one example of an intermediate reward might be blood pressure control. So we might know that if we keep the patient's blood pressure within some range, it’s a good thing and so if you ever see a patient's blood pressure go outside of that range, you have a negative reward associated to that. So that's how you define the reward function. Again the reward function is a function of these states. Here we're going to ignore the actions when defining the rewards. So we have the states, we have the actions, we have the rewards, we have everything we need to define a Markov decision process and now the next step is: how do we learn it? So in lecture 10, Tamara spoke about exploration versus exploitation and the key question there is: you start from no data and you start exploring in the world by performing some actions, seeing what happens, what rewards you get, what states you get to, and as you do more and more exploring, you get more and more data and you use that data to try to learn a policy that gets better and better over time. And there's this question of: do you exploit, meaning do you use the best policy that you have for all future individuals or do you explore, meaning do you keep trying different types of treatments? And the exploration strategy that we spoke about in this class is called the epsilon greedy strategy where, with probability epsilon, you choose an action uniformly at random. Now do you think that strategy would make sense in a healthcare setting?

Any concerns with that? You can enter your response in the chat. Any concerns with using an explore and exploit strategy?

So one concern that I see people are entering is that mistakes might have a higher impact. There might be really big ethical issues with deciding who to use exploratory treatments on and these are all really good points and one can't use this epsilon greedy strategy in the healthcare setting and that's what one of the major challenges is in using reinforcement learning techniques that we saw in class in the healthcare setting. And so I'll get back to what we do in just a second but the tldr of this is that there are a couple of different algorithms that we learn in lecture 10 for learning. The first approach was, let's say, just explore and then learn your transition distribution and then once you've learned your transition distribution using all the data you have, then you just do infinite horizon value iteration in order to learn a good policy. The second approach that was suggested was to estimate the Q function directly from the data that one has. So as we just discussed, one can't typically explore in a healthcare setting and instead what one does is called offline reinforcement learning. It turns out that the two algorithms I just showed you from lecture 10 could be used in an offline setting where all one has are those observed trajectories of state action reward pairs for patients in the retrospective data. So for example, you could use that retrospective data to estimate the transition distribution and then run value iteration or you could also just take pairs of these tuples (s, a, s’, and r), keep presenting them to your Q learning algorithm .You're getting these pairs, instead of from doing epsilon greedy, you're getting them from your observed data and you update your Q values based on those observed batch data. So this is what's known as offline reinforcement learning and that's what we would use in this healthcare context. Now recent reinforcement learning successes in the news, for example, the AlphaGo algorithm which had succeeded at beating the world's best go player led the healthcare community to be really excited about using reinforcement learning and healthcare for problems like the one I just mentioned but it turns out that healthcare is substantially harder than those settings I just described, those game related settings. So for example, one key design choice is: what is in that state space? I showed you one way to try to derive the state space by this k-means clustering approach based on features like the patient's blood pressure, oxygen saturation, and so on but if we had accidentally left out important information there, then the policies that we get out could be really biased and similarly, we just talked about how we can't do epsilon greedy algorithms to learn here, instead one has to only take retrospective data that are available, and so thus we might have very limited data available whereas in these games scenario they had simulators so they could really think about any policy and just run that policy and see how well it does and so those algorithms were substantially more successful as a result. Okay so I already just gave some hints about what makes healthcare different so I'm going to skip these last few slides and I'm going to get to my closing slide. Congratulations, this is the end of 6.036! You've had 13 lectures that walked you through everything from supervised learning to reinforcement learning to unsupervised learning with the k-means algorithm and along the way, we've hinted at how we're really just at the tip of the iceberg. We hope that you now have some of the skills you would need to start using machine learning in an industry position, an internship, and research but one might also want to dive in deeper to learn much more about machine learning and data science. So in terms of where to go to next, I'd like to point out a few courses that you could consider taking subsequent semesters here at MIT. These first two courses, 6.401 and 6.419, are very introductory courses but focus on more data science aspects of machine learning than what we focused on in this course. The next set of four courses, 6.806 up to 6.802, are courses that are at a more advanced level but many of these courses have both undergraduate and graduate versions and they look at applications of machine learning in different scenarios. So for example, 6.871 is (of course, I'm teaching next semester) on machine learning for healthcare which goes into much, much more depth on some of the things you learned in this lecture and it requires 6.036 as a prerequisite. Then there are two more courses I'd like to point out that aren't offered into the fall semester: 6.867 which is the graduate machine learning course and 6.860 which is another graduate course in machine learning which is joint between course 6 and the brain and cognitive sciences department. Both of those courses would be very appropriate courses if you want to do a much deeper dive into the algorithms that you learned about in this course and learn some of the theoretical properties. All right, with that, we're out of time and I want to thank you for joining us for 6.036 this semester and wish you a very good winter break!

Bye.
